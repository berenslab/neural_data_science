{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Neural Data Analysis_\n",
    "\n",
    "Lecturer: Prof. Dr. Philipp Berens\n",
    "\n",
    "Tutors: Sarah Strauss, Ziwei Huang\n",
    "\n",
    "Summer term 2021\n",
    "\n",
    "Student names: *FILL IN YOUR NAMES HERE*\n",
    "\n",
    "# Coding Lab 2\n",
    "\n",
    "If needed, download the data files ```nda_ex_1_*.npy``` from ILIAS and save it in the subfolder ```../data/```. Use a subset of the data for testing and debugging. But be careful not to make it too small, since the algorithm may fail to detect small clusters in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy as sp\n",
    "from scipy.io import loadmat\n",
    "import copy\n",
    "from scipy import linalg\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace by path to your solutions\n",
    "b = np.load('../data/nda_ex_1_features.npy')\n",
    "s = np.load('../data/nda_ex_1_spiketimes.npy')\n",
    "w = np.load('../data/nda_ex_1_waveforms.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Generate toy data\n",
    "\n",
    "Sample 1000 data points from a two dimensional mixture of Gaussian model with three clusters  and the following parameters:\n",
    "\n",
    "$\\mu_1 = \\begin{bmatrix}0\\\\0\\end{bmatrix}, \\Sigma_1 = \\begin{bmatrix}1 & 0\\\\0 & 1\\end{bmatrix}, \\pi_1=0.3$\n",
    "\n",
    "$\\mu_2 = \\begin{bmatrix}5\\\\1\\end{bmatrix}, \\Sigma_2 = \\begin{bmatrix}2 & 1\\\\1 & 2\\end{bmatrix}, \\pi_2=0.5$\n",
    "\n",
    "$\\mu_3 = \\begin{bmatrix}0\\\\4\\end{bmatrix}, \\Sigma_3 = \\begin{bmatrix}1 & -0.5\\\\-0.5 & 1\\end{bmatrix}, \\pi_3=0.2$\n",
    "\n",
    "Plot the sampled data points and indicate in color the cluster each point came from. Plot the cluster means as well.\n",
    "\n",
    "*Grading: 1 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleData(N, m, S, p):\n",
    "#    Generate N samples from a Mixture of Gaussian distribution with\n",
    "#    means m, covariances S and priors p. The function returns the sampled\n",
    "#    datapoints x as well as an indicator for the cluster the point \n",
    "#    originated from. The number of samples is rounded to the nearest integer.\n",
    "#\n",
    "#    m     #components x #dim\n",
    "#    S     #dim x #dim x #components\n",
    "#    p     #components\n",
    "#\n",
    "#    x     N x #dim\n",
    "#    ind   N \n",
    "\n",
    "# fill in your code here\n",
    "    \n",
    "    return (x,ind)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify parameters of Gaussians and run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "m = np.array([[0, 0], [5, 1], [0, 4]])\n",
    "S1 = np.array([[1, 0], [0, 1]])\n",
    "S2 = np.array([[2, 1], [1, 2]])\n",
    "S3 = np.array([[1, -.5], [-.5, 1]])\n",
    "S = np.concatenate((S1[:,:,np.newaxis],\n",
    "                    S2[:,:,np.newaxis],\n",
    "                    S3[:,:,np.newaxis]), axis=2)\n",
    "p = np.array([.3, .5, .2])\n",
    "\n",
    "x, ind = sampleData(N, m, S, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax = plt.subplot(1,1,1, aspect='equal')\n",
    "plt.plot(x[ind==0,0],x[ind==0,1],'.k', markersize=3) \n",
    "plt.plot(x[ind==1,0],x[ind==1,1],'.r', markersize=3) \n",
    "plt.plot(x[ind==2,0],x[ind==2,1],'.b', markersize=3)\n",
    "\n",
    "plt.xlim((-4,10))\n",
    "plt.ylim((-4,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement a Gaussian mixture model\n",
    "\n",
    "Implement the EM algorithm to fit a Gaussian mixture model in `mog()`.  Sort the data points by inferring their class labels from your mixture model (by using maximum a-posteriori classification). Fix the seed of the random number generator to ensure deterministic and reproducible behavior. Test it on the toy dataset specifying the correct number of clusters and make sure the code works correctly. Plot the data points from the toy dataset and indicate in color the cluster each point was assigned to by your model. How does the assignment compare to ground truth? If you run the algorithm multiple times, you will notice that some solutions provide suboptimal clustering solutions - depending on your initialization strategy.  \n",
    "\n",
    "*Grading: 4 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mog(x,k):\n",
    "# Fit Mixture of Gaussian model\n",
    "#   ind, m, S, p = mog(x,k) fits a Mixture of Gaussian model to the data in\n",
    "#   x using k components. The output ind contains the MAP assignments of the\n",
    "#   datapoints in x to the found clusters. The outputs m, S, p contain\n",
    "#   the model parameters.\n",
    "#\n",
    "#   x:     N by D\n",
    "#\n",
    "#   ind:   N by 1\n",
    "#   m:     k by D\n",
    "#   S:     D by D by k\n",
    "#   p:     k by 1\n",
    "\n",
    "    # fill in your code here\n",
    "\n",
    "\n",
    "    return (ind, m, S, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Mixture of Gaussian on toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2, m, S, p = mog(x,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot toy data with cluster assignments and compare to original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = plt.subplot(1,2,1, aspect='equal')\n",
    "plt.plot(x[ind==0,0],x[ind==0,1],'.k', markersize=3) \n",
    "plt.plot(x[ind==1,0],x[ind==1,1],'.r', markersize=3) \n",
    "plt.plot(x[ind==2,0],x[ind==2,1],'.b', markersize=3)\n",
    "\n",
    "plt.xlim((-4,10))\n",
    "plt.ylim((-4,10))\n",
    "plt.title('True labels')\n",
    "\n",
    "ax = plt.subplot(1,2,2, aspect='equal')\n",
    "plt.plot(x[ind2==0,0],x[ind2==0,1],'.k', markersize=3) \n",
    "plt.plot(x[ind2==1,0],x[ind2==1,1],'.r', markersize=3) \n",
    "plt.plot(x[ind2==2,0],x[ind2==2,1],'.b', markersize=3)\n",
    "\n",
    "plt.xlim((-4,10))\n",
    "plt.ylim((-4,10))\n",
    "plt.title('MoG labels')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Model complexity\n",
    "A priori we do not how many neurons we recorded. Extend your algorithm with an automatic procedure to select the appropriate number of mixture components (clusters). Base your decision on the Bayesian Information Criterion:\n",
    "\n",
    "$BIC = -2L+P \\log N,$\n",
    "\n",
    "where $L$ is the log-likelihood of the data under the best model, $P$ is the number of parameters of the model and $N$ is the number of data points. You want to minimize the quantity. Plot the BIC as a function of mixture components. What is the optimal number of clusters on the toy dataset?\n",
    "\n",
    "You can also use the BIC to make your algorithm robust against suboptimal solutions due to local minima. Start the algorithm multiple times and pick the best solutions for extra points. You will notice that this depends a lot on which initialization strategy you use.\n",
    "\n",
    "*Grading: 2 pts + 1 extra pt*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mog_bic(x, m, S):\n",
    "# Compute the BIC for a fitted Mixture of Gaussian model\n",
    "#   bic, LL = mog_bic(x,k) computes the the Bayesian Information \n",
    "#   Criterion value and the log-likelihood of the fitted model.\n",
    "#\n",
    "#   x:     N by D\n",
    "#   m:     k by D\n",
    "#   S:     D by D by k\n",
    "\n",
    "#   bic:   1 by 1\n",
    "#   LL:    1 by 1\n",
    "\n",
    "\n",
    "    # fill in your code here\n",
    "\n",
    "    return (bic, LL)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and compute the BIC for mixture models with different numbers of clusters (e.g., between 2 and 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [2, 3, 4, 5, 6]\n",
    "BIC = np.zeros((3,len(K)))\n",
    "LL = np.zeros((3,len(K)))\n",
    "\n",
    "# run mog and BIC multiple times here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "plt.plot(K,np.min(BIC,axis=0),'s')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('BIC')\n",
    "plt.xticks(K)\n",
    "plt.xlim((1,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Spike sorting using Mixture of Gaussian \n",
    "Run the full algorithm on your set of extracted features (including model complexity selection). Plot the BIC as a function of the number of mixture components on the real data. For the best model, make scatter plots of the first PCs on all four channels (6 plots). Color-code each data point according to its class label in the model with the optimal number of clusters. In addition, indicate the position (mean) of the clusters in your plot. \n",
    "\n",
    "*Grading: 3 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.arange(2,14)\n",
    "BIC = np.zeros(len(K))\n",
    "LL = np.zeros(len(K))\n",
    "\n",
    "for j in np.arange(0,len(K)):\n",
    "    foo, m, S, p = mog(b,K[j])\n",
    "    BIC[j], LL[j] = mog_bic(b, m, S)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit model with lowest BIC and plot data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../data/nda_ex_2_means',m)\n",
    "np.save('../data/nda_ex_2_covs',S)\n",
    "np.save('../data/nda_ex_2_pis',p)\n",
    "np.save('../data/nda_ex_2_labels',a)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
